{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Js0UzG3kqvgu",
        "outputId": "10772ac6-8b57-4bd0-f1ae-05ff5f286486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import glob\n",
        "import dill\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LX1ePM0Pq8Nh",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJOtfXP5AruT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/NNFL/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Qe_nQT-3e1P",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "TEXT = torch.load(PATH+'TEXT.pt',pickle_module=dill)\n",
        "txt_field_AGR = torch.load(PATH+'Personality/AGR_txt.pt',pickle_module = dill)\n",
        "txt_field_CON = torch.load(PATH+'Personality/CON_txt.pt',pickle_module = dill)\n",
        "txt_field_EXT = torch.load(PATH+'Personality/EXT_txt.pt',pickle_module = dill)\n",
        "txt_field_NEU = torch.load(PATH+'Personality/NEU_txt.pt',pickle_module = dill)\n",
        "txt_field_OPN = torch.load(PATH+'Personality/OPN_txt.pt',pickle_module = dill)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zkxtVAmjoOka",
        "colab": {}
      },
      "source": [
        "class sentimentCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim, out_channels = 150, kernel_size = fs)for fs in [4,5]])\n",
        "        self.conv2 = nn.Conv1d(in_channels = 1, out_channels = 100, kernel_size = 3)              \n",
        "        self.fc1 = nn.Linear(200, 100) \n",
        "        self.fc2=nn.Linear(100,1)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        embedded = self.embedding(text)        \n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "\n",
        "        sent_len=embedded.size(2)\n",
        "        padding=3000-sent_len\n",
        "        batch_size=embedded.size(0)\n",
        "        torch_padding=torch.zeros(batch_size,300,padding,dtype = embedded.dtype,device = embedded.device)\n",
        "        lz=[embedded,torch_padding]\n",
        "        zcat = torch.cat(lz, dim = 2)\n",
        "\n",
        "        conved = [F.relu(conv(zcat)) for conv in self.convs]\n",
        "\n",
        "        pooled=[]\n",
        "        for c in conved:\n",
        "          pooled.append(F.max_pool1d(c,c.shape[2]))\n",
        "\n",
        "        pooled = [f.permute(0,2,1) for f in pooled]\n",
        "\n",
        "        pooled2 = [F.max_pool1d(p, 2) for p in pooled]\n",
        "\n",
        "        pooled3 = [F.relu(self.conv2(p1)) for p1 in pooled2]\n",
        "\n",
        "        pooled4=[]\n",
        "        for c in pooled3:\n",
        "            pooled4.append(F.max_pool1d(c,c.shape[2]))\n",
        "\n",
        "        final = torch.cat(pooled4,dim = 1)\n",
        "        final = final.reshape(batch_size,200)\n",
        "        full1 = self.fc1(final)\n",
        "        full2= self.fc2(full1)\n",
        "        return full2\n",
        "\n",
        "class PersonalityCNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim,padding_idx = pad_idx)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim,out_channels = 80,kernel_size = fs) for fs in (3,4,5)])\n",
        "        self.conv2 = nn.Conv1d(in_channels = 1,out_channels = 100,kernel_size = (2))\n",
        "        self.fc1 = nn.Linear(300,80)\n",
        "        self.fc2 = nn.Linear(80,1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "    def forward(self,text):\n",
        "        embedded = self.embedding(text.T)\n",
        "        embedded = embedded.permute(0,2,1)\n",
        "        x=embedded.size(2)\n",
        "        y=3000-x\n",
        "        batch_size=embedded.size(0)\n",
        "        z = torch.zeros(batch_size,300,y,dtype = embedded.dtype,device = embedded.device)\n",
        "        lz=[embedded,z]\n",
        "        zcat = torch.cat(lz, dim = 2,)\n",
        "        conved = [F.relu(conv(zcat)) for conv in self.convs]\n",
        "        pooled2 = []\n",
        "        for c in conved:\n",
        "          pooled2.append(F.max_pool1d(c,c.shape[2]))\n",
        "        pooled2 = [f.permute(0,2,1) for f in pooled2]\n",
        "        pooled = [F.max_pool1d(conv,(2)) for conv in pooled2] #25\n",
        "\n",
        "        pooled2 = [F.relu(self.conv2(p1)) for p1 in pooled]\n",
        "        pooled3 = []\n",
        "        for c in pooled2:\n",
        "          pooled3.append(F.max_pool1d(c,c.shape[2]))\n",
        "        final = torch.cat(pooled3,dim = 1)\n",
        "        final = final.reshape(batch_size,300)\n",
        "        full1 = self.fc1(final)\n",
        "        full2 = self.fc2(full1)\n",
        "        return full2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ScE2gEnlpY4q",
        "outputId": "d80e1730-0891-4dda-d4b6-cbb56a391383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "sentimentModel = sentimentCNN(10002, 300, 0.5, 1)\n",
        "sentimentModel = sentimentModel.to(device)\n",
        "\n",
        "input_dim_agr = len(txt_field_AGR.vocab)\n",
        "embedding_dim = 300\n",
        "pad_idx = txt_field_AGR.vocab.stoi[txt_field_AGR.pad_token]\n",
        "modelAGR = PersonalityCNN(input_dim_agr,embedding_dim,pad_idx)\n",
        "modelAGR.to(device)\n",
        "\n",
        "input_dim_con = len(txt_field_CON.vocab)\n",
        "embedding_dim = 300\n",
        "pad_idx = txt_field_CON.vocab.stoi[txt_field_CON.pad_token]\n",
        "modelCON = PersonalityCNN(input_dim_con,embedding_dim,pad_idx)\n",
        "modelCON.to(device)\n",
        "\n",
        "input_dim_ext = len(txt_field_EXT.vocab)\n",
        "embedding_dim = 300\n",
        "pad_idx = txt_field_EXT.vocab.stoi[txt_field_EXT.pad_token]\n",
        "modelEXT = PersonalityCNN(input_dim_ext,embedding_dim,pad_idx)\n",
        "modelEXT.to(device)\n",
        "\n",
        "input_dim_neu = len(txt_field_NEU.vocab)\n",
        "embedding_dim = 300\n",
        "pad_idx = txt_field_NEU.vocab.stoi[txt_field_NEU.pad_token]\n",
        "modelNEU = PersonalityCNN(input_dim_neu,embedding_dim,pad_idx)\n",
        "modelNEU.to(device)\n",
        "\n",
        "input_dim_opn = len(txt_field_OPN.vocab)\n",
        "embedding_dim = 300\n",
        "pad_idx = txt_field_OPN.vocab.stoi[txt_field_OPN.pad_token]\n",
        "modelOPN = PersonalityCNN(input_dim_opn,embedding_dim,pad_idx)\n",
        "modelOPN.to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PersonalityCNN(\n",
              "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
              "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
              "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
              "  )\n",
              "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
              "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
              "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6PjqCoYqLyE",
        "outputId": "2330d391-b9a1-4cd7-e6bc-25c48ac30108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#This extracts the layers from the pre-trained model\n",
        "sentimentActivation = {}\n",
        "def get_sentiactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        sentimentActivation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "for name, layer in sentimentModel.named_modules():\n",
        "    layer.register_forward_hook(get_sentiactivation(name))\n",
        "\n",
        "AGRActivation = {}\n",
        "def get_AGRactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        AGRActivation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "for name, layer in modelAGR.named_modules():\n",
        "    print(layer)\n",
        "    layer.register_forward_hook(get_AGRactivation(name))\n",
        "\n",
        "CONActivation = {}\n",
        "def get_CONactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        CONActivation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "for name, layer in modelCON.named_modules():\n",
        "    print(layer)\n",
        "    layer.register_forward_hook(get_CONactivation(name))\n",
        "\n",
        "EXTActivation = {}\n",
        "def get_EXTactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        EXTActivation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "for name, layer in modelEXT.named_modules():\n",
        "    print(layer)\n",
        "    layer.register_forward_hook(get_EXTactivation(name))\n",
        "\n",
        "NEUActivation = {}\n",
        "def get_NEUactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        NEUActivation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "for name, layer in modelNEU.named_modules():\n",
        "    print(layer)\n",
        "    layer.register_forward_hook(get_NEUactivation(name))\n",
        "\n",
        "OPNActivation = {}\n",
        "def get_OPNactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        OPNActivation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "for name, layer in modelOPN.named_modules():\n",
        "    print(layer)\n",
        "    layer.register_forward_hook(get_OPNactivation(name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PersonalityCNN(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Embedding(10002, 300, padding_idx=1)\n",
            "ModuleList(\n",
            "  (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "  (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "  (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            ")\n",
            "Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "Linear(in_features=300, out_features=80, bias=True)\n",
            "Linear(in_features=80, out_features=1, bias=True)\n",
            "Dropout(p=0.5, inplace=False)\n",
            "PersonalityCNN(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Embedding(10002, 300, padding_idx=1)\n",
            "ModuleList(\n",
            "  (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "  (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "  (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            ")\n",
            "Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "Linear(in_features=300, out_features=80, bias=True)\n",
            "Linear(in_features=80, out_features=1, bias=True)\n",
            "Dropout(p=0.5, inplace=False)\n",
            "PersonalityCNN(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Embedding(10002, 300, padding_idx=1)\n",
            "ModuleList(\n",
            "  (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "  (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "  (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            ")\n",
            "Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "Linear(in_features=300, out_features=80, bias=True)\n",
            "Linear(in_features=80, out_features=1, bias=True)\n",
            "Dropout(p=0.5, inplace=False)\n",
            "PersonalityCNN(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Embedding(10002, 300, padding_idx=1)\n",
            "ModuleList(\n",
            "  (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "  (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "  (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            ")\n",
            "Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "Linear(in_features=300, out_features=80, bias=True)\n",
            "Linear(in_features=80, out_features=1, bias=True)\n",
            "Dropout(p=0.5, inplace=False)\n",
            "PersonalityCNN(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Embedding(10002, 300, padding_idx=1)\n",
            "ModuleList(\n",
            "  (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "  (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "  (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            ")\n",
            "Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "Linear(in_features=300, out_features=80, bias=True)\n",
            "Linear(in_features=80, out_features=1, bias=True)\n",
            "Dropout(p=0.5, inplace=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5m5-06paqYp-",
        "colab": {}
      },
      "source": [
        "def extract_sentimentfeatures(model,sentence,min_len=5):\n",
        "  model.eval()\n",
        "  tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "  if len(tokenized)>3000:\n",
        "    tokenized=tokenized[:3000]\n",
        "  if len(tokenized) < min_len:\n",
        "      tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  model(tensor)\n",
        "  return sentimentActivation['fc1']\n",
        "\n",
        "def tokenize(s):\n",
        "    return re.findall(r\"[\\w']+|[.,!?;]\",s)\n",
        "    \n",
        "def breakEssay(essay):\n",
        "  l=[]\n",
        "  curr=\"\"\n",
        "  words=word_tokenize(essay)\n",
        "  ct=0\n",
        "  for word in words:\n",
        "      ct+=1\n",
        "      if word==\".\" or word==\"!\" or word==\"?\" or ct%50==0:\n",
        "          if len(curr)==0:\n",
        "              curr=\"\"\n",
        "              ct=0\n",
        "              continue\n",
        "          curr+=word\n",
        "          l.append(curr)\n",
        "          curr=\"\"\n",
        "          ct=0\n",
        "          continue\n",
        "      curr+=word+\" \"\n",
        "  if len(l) == 0:\n",
        "    l.append(essay)\n",
        "  return l\n",
        "\n",
        "def extract_personalityfeatures(text,model,txt,keydict,min_len=5):\n",
        "  model.eval()\n",
        "  tokenized = [tok for tok in tokenize(text)]\n",
        "  if len(tokenized)>3000:\n",
        "    tokenized=tokenized[:3000]\n",
        "  if len(tokenized) < min_len:\n",
        "      tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "  indexed = [txt.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  tensor = tensor.T\n",
        "  model(tensor)\n",
        "  return keydict['fc1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6LDBrds9Q_yv",
        "outputId": "20c061b8-2ec2-44c4-c128-99cfc56b7251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#All the models are loaded here\n",
        "sentimentModel.load_state_dict(torch.load(PATH+'sentimentModel.pt',pickle_module=dill))\n",
        "modelAGR.load_state_dict(torch.load(PATH+'Personality/AGR.pt',pickle_module = dill))\n",
        "modelCON.load_state_dict(torch.load(PATH+'Personality/CON.pt',pickle_module = dill))\n",
        "modelEXT.load_state_dict(torch.load(PATH+'Personality/EXT.pt',pickle_module = dill))\n",
        "modelNEU.load_state_dict(torch.load(PATH+'Personality/NEU.pt',pickle_module = dill))\n",
        "modelOPN.load_state_dict(torch.load(PATH+'Personality/OPN.pt',pickle_module = dill))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "waSp_O8ORKkJ",
        "colab": {}
      },
      "source": [
        "#This loads the Amazon Reviews\n",
        "df = pd.read_csv(PATH+'reviews_w_stars.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xJs6pgBOPLkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This extracts the Sentiment and Personality features from the Amazon Reviews\n",
        "feat = []\n",
        "for i in range(df.shape[0]):\n",
        "    temp = []\n",
        "    x1 = extract_sentimentfeatures(sentimentModel, str(df.iloc[i]['Reviews'])).cpu().numpy()\n",
        "    x2 = extract_personalityfeatures(str(df.iloc[i]['Reviews']),modelAGR,txt_field_AGR,AGRActivation).cpu().numpy()\n",
        "    x3 = extract_personalityfeatures(str(df.iloc[i]['Reviews']),modelCON,txt_field_CON,CONActivation).cpu().numpy()\n",
        "    x4 = extract_personalityfeatures(str(df.iloc[i]['Reviews']),modelEXT,txt_field_EXT,EXTActivation).cpu().numpy()\n",
        "    x5 = extract_personalityfeatures(str(df.iloc[i]['Reviews']),modelNEU,txt_field_NEU,NEUActivation).cpu().numpy()\n",
        "    x6 = extract_personalityfeatures(str(df.iloc[i]['Reviews']),modelOPN,txt_field_OPN,OPNActivation).cpu().numpy()\n",
        "    temp = np.concatenate((x1,x2,x3,x4,x5,x6), axis = 1)\n",
        "    feat.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kV9oybx8PLkQ",
        "colab_type": "code",
        "outputId": "31cc239e-b83d-49ab-9987-db5502aacba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#This restructures the features extracted and appends the relevant data\n",
        "featdf = pd.DataFrame(np.array(feat).reshape(-1, 500))\n",
        "featdf[500] = df['Stars']\n",
        "featdf[501] = df['Type']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           0         1         2         3    ...       498       499  500  501\n",
            "0     0.208791  1.040853 -1.041554 -1.404897  ... -0.269785 -0.034902    1    1\n",
            "1    -0.409257 -4.044721 -1.625169  2.561371  ... -0.498094  0.863928    1    1\n",
            "2     0.127271 -3.306749 -1.006750  1.578318  ... -0.649528  0.135815    1    1\n",
            "3     0.288411 -2.402842 -1.291371  0.591093  ...  0.063336 -0.097582    1    1\n",
            "4    -0.068595 -0.579789 -0.773463 -0.013373  ... -0.388713  0.233158    5    1\n",
            "...        ...       ...       ...       ...  ...       ...       ...  ...  ...\n",
            "1249  0.252947  3.535869 -0.279142 -2.632548  ... -0.208582  0.472243    4    0\n",
            "1250  0.241757  2.252195 -1.353155 -2.207019  ... -0.157103  0.509930    5    0\n",
            "1251  0.813260  8.406722 -1.591205 -6.307390  ... -0.449360  0.632835    5    0\n",
            "1252  0.345078  7.167039 -1.121790 -5.279661  ... -0.445722  0.585099    5    0\n",
            "1253  0.069935  2.689093 -0.344016 -1.276075  ... -0.421279  0.679173    5    0\n",
            "\n",
            "[1254 rows x 502 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xryDL5SPLkS",
        "colab_type": "code",
        "outputId": "a293b4a5-0ce7-4fba-b046-85a3218dbf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#This is the SVM\n",
        "X = featdf.iloc[:,:501]\n",
        "y = featdf[501]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
        "clf = SVC(gamma = 'scale')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test,y_pred))\n",
        "print('Accuracy:',accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[73  5]\n",
            " [10 38]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91        78\n",
            "           1       0.88      0.79      0.84        48\n",
            "\n",
            "    accuracy                           0.88       126\n",
            "   macro avg       0.88      0.86      0.87       126\n",
            "weighted avg       0.88      0.88      0.88       126\n",
            "\n",
            "Accuracy: 0.8809523809523809\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sarcasm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}