{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K7rCXwkMu2bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb99ab6f-d1be-475c-da96-497066e3d2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (3.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "import string\n",
        "LANGUAGE = string.ascii_lowercase + string.punctuation + ' '\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "LEMMATIZER = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "# from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer \n",
        "# ps = PorterStemmer()\n",
        "# # ps = SnowballStemmer(language='english')\n",
        "# # ps = LancasterStemmer()\n",
        "# # ps = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMMON_ABBREV = {\n",
        "    \"411\":\"information\",\n",
        "    \"af\":\"as fuck\",\n",
        "    \"afaik\":\"as far as i know\",\n",
        "    \"ama\":\"ask me anything\",\n",
        "    \"asl\":\"age / sex / location\",\n",
        "    \"b4\":\"before\",\n",
        "    \"bae\":\"before anyone else\",\n",
        "    \"b/c\":\"because\",\n",
        "    \"bc\":\"because\",\n",
        "    \"bff\":\"best friends forever\",\n",
        "    \"brb\":\"be right back\",\n",
        "    \"btaim\":\"be that as it may\",\n",
        "    \"bts\":\"behind the scenes\",\n",
        "    \"btw\":\"by the way\",\n",
        "    \"dae\":\"does anyone know?\",\n",
        "    \"dftba\":\"don’t forget to be awesome\",\n",
        "    \"dyk\":\"did you know\",\n",
        "    \"eli5\":\"explain like i am 5 ( years old )\",\n",
        "    \"f2f\":\"face to face\",\n",
        "    \"fbf\":\"flashback friday\",\n",
        "    \"ffs\":\"for fuck’s sake\",\n",
        "    \"fml\":\"fuck my life\",\n",
        "    \"fomo\":\"fear of missing out\",\n",
        "    \"ftfy\":\"fixed that for you\",\n",
        "    \"ftw\":\"for the win\",\n",
        "    \"futab\":\"feet up, take a break\",\n",
        "    \"fwiw\":\"for what it is worth\",\n",
        "    \"fyi\":\"for your information\",\n",
        "    \"gg\":\"good game\",\n",
        "    \"gr8\":\"great\",\n",
        "    \"gtg\":\"got to go\",\n",
        "    \"gtr\":\"got to run\",\n",
        "    \"h/t\":\"hat tip\",\n",
        "    \"hbd\":\"happy birthday\",\n",
        "    \"hth\":\"here to help / happy to help\",\n",
        "    \"hmb\":\"hit me back\",\n",
        "    \"hmu\":\"hit me up\",\n",
        "    \"ianad\":\"i am not a doctor\",\n",
        "    \"ianal\":\"i am not a lawyer\",\n",
        "    \"icymi\":\"in case you missed it\",\n",
        "    \"idc\":\"i do not care\",\n",
        "    \"idk\":\"i do not know\",\n",
        "    \"ikr\":\"i know, right?\",\n",
        "    \"ily\":\"i love you\",\n",
        "    \"imho\":\"in my humble opinion\",\n",
        "    \"imo\":\"in my opinion\",\n",
        "    \"imy\":\"i miss you\",\n",
        "    \"irl\":\"in real life\",\n",
        "    \"iso\":\"in search of\",\n",
        "    \"jk\":\"just kidding\",\n",
        "    \"jtm\":\"just the messenger\",\n",
        "    \"l8\":\"late\",\n",
        "    \"lmao\":\"laughing my ass off\",\n",
        "    \"lmk\":\"let me know\",\n",
        "    \"lol\":\"laughing out loud\",\n",
        "    \"mtfbwy\":\"may the force be with you\",\n",
        "    \"myob\":\"mind your own business\",\n",
        "    \"nbd\":\"no big deal\",\n",
        "    \"nm\":\"not much\",\n",
        "    \"nsfw\":\"not safe for work\",\n",
        "    \"nvm\":\"nevermind\",\n",
        "    \"nyt\":\"name your trade\",\n",
        "    \"obv\":\"obviously\",\n",
        "    \"oh\":\"overheard\",\n",
        "    \"omg\":\"oh my god\",\n",
        "    \"omw\":\"on my way\",\n",
        "    \"orly\":\"oh really?\",\n",
        "    \"pls\":\"please\",\n",
        "    \"ppl\":\"people\",\n",
        "    \"potd\":\"photo of the day\",\n",
        "    \"psa\":\"public service announcement\",\n",
        "    \"qotd\":\"quote of the day\",\n",
        "    \"rn\":\"right now\",\n",
        "    \"rofl\":\"rolling on the floor laughing\",\n",
        "    \"srsly\":\"seriously\",\n",
        "    \"smh\":\"shaking my head\",\n",
        "    \"tbh\":\"to be honest\",\n",
        "    \"tbt\":\"throwback thursday\",\n",
        "    \"tfw\":\"that feeling when / the face when\",\n",
        "    \"tgif\":\"thank god it’s friday\",\n",
        "    \"thx\":\"thanks\",\n",
        "    \"til\":\"today i learned\",\n",
        "    \"tl;dr\":\"too long; did not read\",\n",
        "    \"tmi\":\"too much information\",\n",
        "    \"ty\":\"thank you\",\n",
        "    \"wbu\":\"what about you?\",\n",
        "    \"wbw\":\"wayback wednesday\",\n",
        "    \"wfh\":\"working from home\",\n",
        "    \"wtf\":\"what the fuck\",\n",
        "    \"wyd\":\"what are you doing?\",\n",
        "    \"yolo\":\"you only live once\",\n",
        "    \"ysk\":\"you should know\",\n",
        "    \"yw\":\"you are welcome\"\n",
        " }"
      ],
      "metadata": {
        "id": "eE-ZDppXtJ7X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url):\n",
        "    \"\"\"\n",
        "    input : url to zip files of amazon customer reviews\n",
        "            Eg: \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Wireless_v1_00.tsv.gz\"\n",
        "    output : path to downloaded file\n",
        "             Eg: '../data/dataset/sample_us.tsv'\n",
        "    \"\"\"\n",
        "    # import pdb;pdb.set_trace()\n",
        "    # path = '../data/dataset'\n",
        "    # zip_path = path + '/' + url.split('/')[-1]\n",
        "    zip_path = url.split('/')[-1]\n",
        "    unzip_path = zip_path.replace(\".gz\",'')\n",
        "\n",
        "    if not os.path.exists(zip_path): #zip file not present \n",
        "        if not os.path.exists(unzip_path):\n",
        "            print(\"Downloading ZIP file becasue File does not exist\")\n",
        "            filename = wget.download(url)\n",
        "            print(filename)\n",
        "            print(\"Dowload Complete\\n\\nInitiating Decompression\")\n",
        "            tsv_path = unzip(filename)\n",
        "            print(tsv_path)\n",
        "            print(\"Decompression Complete\")\n",
        "            # return filename\n",
        "        else:\n",
        "            print(\"Zip File Already Downloaded and Decompressed\")\n",
        "            tsv_path = unzip_path\n",
        "    else: # zip file present already\n",
        "        if os.path.exists(unzip_path):\n",
        "            print(\"Zip File Already Downloaded and Decompressed\")\n",
        "            tsv_path = unzip_path\n",
        "        else:\n",
        "            print(\"Zip File Already Downloaded.\\n\\nInitiating Decompression\")\n",
        "            tsv_path = unzip(zip_path)\n",
        "            print(tsv_path)\n",
        "            print(\"Decompression Complete\")\n",
        "\n",
        "    return tsv_path\n"
      ],
      "metadata": {
        "id": "_8hSW1Frttla"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete(filename):\n",
        "    \"\"\"\n",
        "    input : filepath to be deleted\n",
        "            Eg: \"\"\n",
        "    output : None\n",
        "    \"\"\"\n",
        "    if os.path.exists(filename):\n",
        "        os.remove(filename)\n",
        "    else:\n",
        "        print(\"The file does not exist:\\t\" + filename)\n",
        "    return None"
      ],
      "metadata": {
        "id": "xu9XgyDwuzla"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip(infile):\n",
        "    \"\"\"\n",
        "    input : just the filename to be unzipped. \n",
        "            Accpeted file type : .gz\n",
        "            Eg: \".gz\"\n",
        "    output : name of unzipped file\n",
        "             Eg:\n",
        "    \"\"\"\n",
        "    # infile = '../data/dataset/' + filename.split('/')[-1]\n",
        "    if infile.endswith('.gz'):\n",
        "        tofile = infile.replace('.gz','')\n",
        "\n",
        "        with open(infile, 'rb') as inf, open(tofile, 'w', encoding='utf8') as tof:\n",
        "            decom_str = gzip.decompress(inf.read()).decode('utf-8')\n",
        "            tof.write(decom_str)\n",
        "        delete(infile)\n",
        "        return tofile\n",
        "    else:\n",
        "        return infile"
      ],
      "metadata": {
        "id": "mbwCQpW3u0l3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filename):\n",
        "    \"\"\"\n",
        "    input : path of tsv file to be loaded. \n",
        "            Eg: \"\"\n",
        "    output : dataframe with tsv dataset loaded\n",
        "    \"\"\"\n",
        "    # import pdb;pdb.set_trace()\n",
        "    ## based on pandas version , one of the two syntaxes below should run\n",
        "    print(filename)\n",
        "    df = pd.read_csv(filename, sep='\\t', index_col = False, on_bad_lines='skip')\n",
        "    # df = pd.read_csv(filename, sep='\\t', index_col = False, error_bad_lines='skip')\n",
        "    print(df.shape)\n",
        "    return df"
      ],
      "metadata": {
        "id": "OGAG_vb_u5D3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(sent):\n",
        "    #converting all tokens to lowercase\n",
        "    sent = str(sent).lower()\n",
        "    #replace_acronyms\n",
        "    sent = \" \".join([COMMON_ABBREV[each] if each in COMMON_ABBREV else each for each in sent.split()])\n",
        "    #replacing website links\n",
        "    sent = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)\", \"\", sent)\n",
        "    #removing stopwords\n",
        "    sent = remove_stopwords(sent)\n",
        "    #stemming\n",
        "    # sent = \" \".join([ps.stem(word) for word in word_tokenize(sent)])\n",
        "    #lemmatizing\n",
        "    sent = \" \".join([LEMMATIZER.lemmatize(word) for word in word_tokenize(sent)])\n",
        "    #to filter out unicode or foreign characters\n",
        "    sent = \"\".join([char for char in sent if char in LANGUAGE])\n",
        "    #removing 's occurences\n",
        "    sent = sent.replace(\"'s\", \"\")\n",
        "    #replacing words ending in \"n't\" with \"word not\"\n",
        "    sent = sent.replace(\"wont\", \"will not\").replace(\"won't\", \"will not\").replace(\"cant\", \"can not\")\n",
        "    sent = sent.replace(\"can't\", \"can not\")\n",
        "    sent = re.sub(r\"([a-zA-z])(n't)\", r\"\\1 not\", sent)\n",
        "    sent = re.sub(r\"(would|could|is|should)(nt)\", r\"\\1 not\", sent)\n",
        "    #remove all HTML tags\n",
        "    sent = re.sub(r\"<.*?>\", \" \", sent)\n",
        "    #replacing multiple punctuations with single occurrence\n",
        "    sent = re.sub(r\"\\.+(\\s?\\.+)*\", \".\", sent)\n",
        "    sent = re.sub(r\"\\!+\", \"!\", sent)\n",
        "    sent = re.sub(r\"=+\", \"=\", sent)\n",
        "    sent = re.sub(r\"_+\", \"_\", sent)\n",
        "    #introducing space after punctuation if not already there\n",
        "    sent = re.sub(r\"([,\\.\\\"'\\?\\-:\\(\\)\\\\\\/=\\*\\!_&#])(?!\\s)\", r\"\\1 \", sent)\n",
        "    #introducing space before punctuation if not already there\n",
        "    sent = re.sub(r\"(?<!\\s)([,\\.\\\"'\\?\\-:\\(\\)\\\\\\/=\\!\\*_])\", r\" \\1\", sent)\n",
        "    #replacing words with more than 2 consecutive same character with two same characters\n",
        "    sent = re.sub(r\"([a-z])\\1{1,}\", r\"\\1\\1\", sent)\n",
        "    #replacing multiple spaces with single space\n",
        "    sent = re.sub(r\"\\s+\", r\" \", sent)\n",
        "    \n",
        "    return sent"
      ],
      "metadata": {
        "id": "nSnwQWpPu8Vc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(sample):\n",
        "    \"\"\"\n",
        "    input : url to zip files of amazon customer reviews\n",
        "            Eg: \"\"\n",
        "    output : filename\n",
        "             Eg:\n",
        "    \"\"\"\n",
        "    # download_file = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv'\n",
        "    # download_file = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Wireless_v1_00.tsv.gz'\n",
        "    # import pdb;pdb.set_trace()\n",
        "    if sample:\n",
        "        data = ['https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv']\n",
        "    else: \n",
        "        data = [\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Wireless_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Watches_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Video_Games_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Video_DVD_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Video_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Toys_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Tools_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Sports_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Software_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Shoes_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Pet_Products_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_PC_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Outdoors_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Music_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Mobile_Apps_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Major_Appliances_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Luggage_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Lawn_and_Garden_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Home_Entertainment_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Home_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Health_Personal_Care_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Grocery_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Furniture_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Electronics_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_01.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Baby_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Automotive_v1_00.tsv.gz',\n",
        "            'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Apparel_v1_00.tsv.gz'\n",
        "            ]\n",
        "    for url in data:\n",
        "        print(\"URL >>>>   \" + url)\n",
        "        tsv_path = download_file(url)\n",
        "        print(\"Loading dataset from >>> \", tsv_path)\n",
        "        df = load_dataset(tsv_path)\n",
        "        #removing rows with null in the following two columns\n",
        "        print(\"BEFORE REMOVING NA IN review_body >>>>>\")\n",
        "        print(df.shape)\n",
        "        df = df[df['review_body'].notna()]\n",
        "        print(\"AFTER REMOVING NA IN review_body >>>>>\")\n",
        "        print(df.shape)\n",
        "        df = df[df['review_headline'].notna()]\n",
        "        print(\"AFTER REMOVING NA IN review_headline >>>>>\")\n",
        "        print(df.shape)\n",
        "        tofile = tsv_path.replace('.tsv','_trim.tsv')\n",
        "        df.to_csv(tofile, sep = '\\t', index=False)\n",
        "        print('created file >>  \\t',tofile)\n",
        "\n",
        "        #applying cleaning procedures to review_headline and review_body\n",
        "        df['clean_review_headline'] = df.apply(lambda df: preprocess(df['review_headline']), axis=1)\n",
        "        df['clean_review_body'] = df.apply(lambda df: preprocess(df['review_body']), axis=1)\n",
        "\n",
        "        #Converting 5 star ratings to binary representation. \n",
        "        #Rating >=3 is positive i.e. 1\n",
        "        #Rating <3 is negative i.e. 0\n",
        "\n",
        "        df[\"Sentiment\"] = df[\"star_rating\"].apply(lambda score: \"negative\" if int(score) < 3 else \"positive\")\n",
        "        df['Sentiment'] = df['Sentiment'].map({'positive':1, 'negative':0})\n",
        "\n",
        "        tofile = tsv_path.replace('.tsv', '_clean.tsv')\n",
        "        df.to_csv(tofile, sep = '\\t', index=False)\n",
        "        print('created file >>  \\t',tofile)\n"
      ],
      "metadata": {
        "id": "p73xalMlwH2A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRIMARY CELL TO TEST ABOVE FUNCTIONS"
      ],
      "metadata": {
        "id": "-OgGzyzzh0t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set choice to 2 to run with real data\n",
        "choice = 1\n",
        "# print(args)\n",
        "sample = False\n",
        "if  choice == 1:\n",
        "    sample = True\n",
        "    print(\"Running with sample data\")\n",
        "    main(sample)\n",
        "elif choice == 2:\n",
        "    print(\"Running with real data\")\n",
        "    main(sample)\n",
        "else:\n",
        "    print('Choice not supported')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FQeItwawPhp",
        "outputId": "fea298e6-38f6-4b8c-9a58-1a496f2be548"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with sample data\n",
            "URL >>>>   https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\n",
            "Zip File Already Downloaded and Decompressed\n",
            "Loading dataset from >>>  sample_us.tsv\n",
            "sample_us.tsv\n",
            "(49, 15)\n",
            "BEFORE REMOVING NA IN review_body >>>>>\n",
            "(49, 15)\n",
            "AFTER REMOVING NA IN review_body >>>>>\n",
            "(49, 15)\n",
            "AFTER REMOVING NA IN review_headline >>>>>\n",
            "(49, 15)\n",
            "created file >>  \t sample_us_trim.tsv\n",
            "created file >>  \t sample_us_clean.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sample_us_clean.tsv', sep='\\t', index_col = False, on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "NXwpY1hodY37"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "FfMWfgqxdYo9",
        "outputId": "210c83e7-7555-4975-8ddb-aeb0c7dceb46"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0          US     18778586   RDIJS7QYB6XNR  B00EDBY7X8       122952789   \n",
              "1          US     24769659  R36ED1U38IELG8  B00D7JFOPC       952062646   \n",
              "2          US     44331596   R1UE3RPRGCOLD  B002LHA74O       818126353   \n",
              "3          US     23310293  R298788GS6I901  B00ARPLCGY       261944918   \n",
              "4          US     38745832    RNX4EXOBBPN5  B00UZOPOFW       717410439   \n",
              "\n",
              "                                       product_title product_category  \\\n",
              "0                         Monopoly Junior Board Game             Toys   \n",
              "1  56 Pieces of Wooden Train Track Compatible wit...             Toys   \n",
              "2         Super Jumbo Playing Cards by S&S Worldwide             Toys   \n",
              "3           Barbie Doll and Fashions Barbie Gift Set             Toys   \n",
              "4  Emazing Lights eLite Flow Glow Sticks - Spinni...             Toys   \n",
              "\n",
              "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
              "0            5              0            0    N                 Y   \n",
              "1            5              0            0    N                 Y   \n",
              "2            2              1            1    N                 Y   \n",
              "3            5              0            0    N                 Y   \n",
              "4            1              1            1    N                 Y   \n",
              "\n",
              "                                     review_headline  \\\n",
              "0                                         Five Stars   \n",
              "1              Good quality track at excellent price   \n",
              "2                                          Two Stars   \n",
              "3  my daughter loved it and i liked the price and...   \n",
              "4                                    DONT BUY THESE!   \n",
              "\n",
              "                                         review_body review_date  \\\n",
              "0                                       Excellent!!!  2015-08-31   \n",
              "1  Great quality wooden track (better than some o...  2015-08-31   \n",
              "2                  Cards are not as big as pictured.  2015-08-31   \n",
              "3  my daughter loved it and i liked the price and...  2015-08-31   \n",
              "4  Do not buy these! They break very fast I spun ...  2015-08-31   \n",
              "\n",
              "                clean_review_headline  \\\n",
              "0                                star   \n",
              "1  good quality track excellent price   \n",
              "2                                star   \n",
              "3  daughter loved liked price came .    \n",
              "4                   dont buy these !    \n",
              "\n",
              "                                   clean_review_body  Sentiment  \n",
              "0                                   excellent ! ! !           1  \n",
              "1  great quality wooden track ( better tried ) . ...          1  \n",
              "2                               card big pictured .           0  \n",
              "3  daughter loved liked price came shopping ton p...          1  \n",
              "4  buy these ! break fast spun minute end flew do...          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ec63215-0b82-4a40-aae2-b34d1abd16b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>clean_review_headline</th>\n",
              "      <th>clean_review_body</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>18778586</td>\n",
              "      <td>RDIJS7QYB6XNR</td>\n",
              "      <td>B00EDBY7X8</td>\n",
              "      <td>122952789</td>\n",
              "      <td>Monopoly Junior Board Game</td>\n",
              "      <td>Toys</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Excellent!!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>star</td>\n",
              "      <td>excellent ! ! !</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>24769659</td>\n",
              "      <td>R36ED1U38IELG8</td>\n",
              "      <td>B00D7JFOPC</td>\n",
              "      <td>952062646</td>\n",
              "      <td>56 Pieces of Wooden Train Track Compatible wit...</td>\n",
              "      <td>Toys</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Good quality track at excellent price</td>\n",
              "      <td>Great quality wooden track (better than some o...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>good quality track excellent price</td>\n",
              "      <td>great quality wooden track ( better tried ) . ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>44331596</td>\n",
              "      <td>R1UE3RPRGCOLD</td>\n",
              "      <td>B002LHA74O</td>\n",
              "      <td>818126353</td>\n",
              "      <td>Super Jumbo Playing Cards by S&amp;S Worldwide</td>\n",
              "      <td>Toys</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Two Stars</td>\n",
              "      <td>Cards are not as big as pictured.</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>star</td>\n",
              "      <td>card big pictured .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>23310293</td>\n",
              "      <td>R298788GS6I901</td>\n",
              "      <td>B00ARPLCGY</td>\n",
              "      <td>261944918</td>\n",
              "      <td>Barbie Doll and Fashions Barbie Gift Set</td>\n",
              "      <td>Toys</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>my daughter loved it and i liked the price and...</td>\n",
              "      <td>my daughter loved it and i liked the price and...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>daughter loved liked price came .</td>\n",
              "      <td>daughter loved liked price came shopping ton p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>38745832</td>\n",
              "      <td>RNX4EXOBBPN5</td>\n",
              "      <td>B00UZOPOFW</td>\n",
              "      <td>717410439</td>\n",
              "      <td>Emazing Lights eLite Flow Glow Sticks - Spinni...</td>\n",
              "      <td>Toys</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>DONT BUY THESE!</td>\n",
              "      <td>Do not buy these! They break very fast I spun ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>dont buy these !</td>\n",
              "      <td>buy these ! break fast spun minute end flew do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec63215-0b82-4a40-aae2-b34d1abd16b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ec63215-0b82-4a40-aae2-b34d1abd16b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ec63215-0b82-4a40-aae2-b34d1abd16b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}